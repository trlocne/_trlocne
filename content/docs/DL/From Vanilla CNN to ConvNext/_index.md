---
title: "From Vanilla CNN to ConvNext"
type: docs
weight: "4"
math: true
comments: true
password: "aiovn"
blog: true
---

## 1. CNN: Basic Concepts

![alt text](image-6.png 'overview of CNN')

{{% details title="CNN" closed="true" %}}
![alt text](image.png)

![alt text](image-1.png)

CNN lÃ  má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sá»­ dá»¥ng trong Deep Learning, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ nháº­n dáº¡ng vÃ  phÃ¢n loáº¡i áº£nh. CNN Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ nháº­n dáº¡ng vÃ  phÃ¢n loáº¡i áº£nh dá»±a trÃªn cáº¥u trÃºc cá»§a nÃ£o ngÆ°á»i. CNN sá»­ dá»¥ng cÃ¡c **lá»›p convolutional** Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng cá»§a áº£nh, cÃ¡c **lá»›p pooling** Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c cá»§a áº£nh vÃ  cÃ¡c lá»›p **fully connected** Ä‘á»ƒ phÃ¢n loáº¡i áº£nh.

![alt text](image-2.png)

á» cÃ¡c lá»›p trong CNN, má»—i lá»›p sáº½ thá»±c hiá»‡n má»™t sá»‘ phÃ©p toÃ¡n nháº¥t Ä‘á»‹nh. Cá»¥ thá»ƒ, má»—i lá»›p sáº½ thá»±c hiá»‡n cÃ¡c phÃ©p toÃ¡n sau:

1. **Convolutional Layer**: Lá»›p nÃ y sáº½ thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p giá»¯a áº£nh Ä‘áº§u vÃ o vÃ  cÃ¡c bá»™ lá»c (filter) Ä‘á»ƒ táº¡o ra cÃ¡c feature maps. CÃ¡c feature maps nÃ y sáº½ chá»©a cÃ¡c Ä‘áº·c trÆ°ng cá»§a áº£nh nhÆ° cáº¡nh, gÃ³c, texture, v.v.
2. **Activation Function**: Lá»›p nÃ y sáº½ thá»±c hiá»‡n phÃ©p kÃ­ch hoáº¡t (activation) trÃªn cÃ¡c feature maps Ä‘á»ƒ táº¡o ra cÃ¡c feature maps Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t.
3. **Pooling Layer**: Lá»›p nÃ y sáº½ thá»±c hiá»‡n phÃ©p pooling (max pooling hoáº·c average pooling) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c cá»§a feature maps.
4. **Fully Connected Layer**: Lá»›p nÃ y sáº½ thá»±c hiá»‡n phÃ©p nhÃ¢n ma tráº­n giá»¯a feature maps Ä‘Ã£ Ä‘Æ°á»£c flatten vÃ  ma tráº­n trá»ng sá»‘ Ä‘á»ƒ phÃ¢n loáº¡i áº£nh.
 
{{< callout type="info" >}}
CÃ¡c lá»›p CNN cÃ ng sÃ¢u thÃ¬ trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng hÃ¬nh áº£nh nhÆ° Ä‘Æ°á»ng tháº³ng, cáº¡nh viÃªn, v.v. CÃ¡c lá»›p cao hÆ¡n tÃ¬m hiá»ƒu nhiá»u Ä‘áº·c trÆ°ng trá»«u tÆ°á»£ng hÆ¡n nhÆ° hÃ¬nh dáº¡ng cá»§a hÃ¬nh áº£nh.
{{< /callout >}}
{{% /details %}}

{{% details title="CÃ¡c phÃ©p toÃ¡n cÆ¡ báº£n cá»§a CNN" closed="true" %}}

![alt text](image-3.png)

Reception feild lÃ  káº¿t quáº£ cá»§a viá»‡c Ã¡p dá»¥ng phÃ©p toÃ¡n convolutional vÃ  pooling.

![alt text](image-4.png)

![alt text](image-5.png)
{{% /details %}}


## 2. LetNet

![alt text](image-7.png)

**LetNet** lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh CNN Ä‘áº§u tiÃªn Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Yann LeCun vÃ o nÄƒm 1998. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ nháº­n dáº¡ng vÃ  phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay trong bá»™ dá»¯ liá»‡u MNIST. MÃ´ hÃ¬nh nÃ y bao gá»“m 7 lá»›p, trong Ä‘Ã³ cÃ³ 3 lá»›p convolutional, 2 lá»›p pooling vÃ  2 lá»›p fully connected.

CÃ¡c kÃ­ hiá»‡u trong hÃ¬nh:
+ C: Convolutional Layer
+ S: Subsampling Layer
+ F: Fully Connected Layer

{{< callout emoji="" >}}
  Thay vÃ¬ sá»­ dá»¥ng flatten Ä‘á»ƒ chuyá»ƒn tá»« lá»›p convolutional sang lá»›p fully connected thÃ¬ ngta sá»­ dá»¥ng conv 1x1 Ä‘á»ƒ lÃ m viá»‡c flatten.
{{< /callout >}}

  
{{% details title="C1: 6@28x28" closed="true" %}}
![alt text](image-8.png)
{{% /details %}}

{{% details title="S2: 6@14x14" closed="true" %}}
![alt text](image-9.png)

Thay vÃ¬ sá»­ dá»¥ng max pooling bÃ¬nh thÆ°á»ng, LeNet sá»­ dá»¥ng **parameterized pooling appoarch**. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh cÃ³ thÃªm tham sá»‘ Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh, cho mÃ´ hÃ¬nh cÃ³ thá»ƒ linh hoáº¡t hÆ¡n trong viá»‡c há»c cÃ¡c Ä‘áº·c trÆ°ng.

<img src='image-10.png' width='300px'>

+ sum lÃ  tá»•ng táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ trong vÃ¹ng pooling.

{{% /details %}}

{{% details title="C3: 16@10x10" closed="true" %}}
![alt text](image-11.png)

Lenet sá»­ dá»¥ng kernel 5x5 Ä‘á»ƒ tÃ¬m ra Ä‘áº·c trÆ°ng cá»§a áº£nh. channel cá»§a filter lÃ  5x5xc lÃ  sá»‘ channel cá»§a input. LeNet cÃ³ má»™t cÃ¡ch tiáº¿p cáº­n khÃ¡c Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘.

![alt text](image-12.png)

CÃ¡c index tá»« [0..15] lÃ  cÃ¡c channel output. cÃ¡c index tá»« [0..5] lÃ  cÃ¡c input channel vá»›i cÃ¡c filter khÃ¡c nhau. Giáº£ sá»­ output channel 0 Ä‘Æ°á»£c tÃ­ch cháº­p tá»« input channel 0, 2, 3. Tá»« hÃ¬nh áº£nh ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c ráº±ng cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c giáº£m Ä‘i má»™t pháº§n.

{{% /details %}}

{{% details title="C5: layer 120" closed="true" %}}
![alt text](image-13.png)

Thay vÃ¬ sá»­ dá»¥ng flatten, LeNet sá»­ dá»¥ng conv 1x1 Ä‘á»ƒ lÃ m viá»‡c flatten. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh cÃ³ thÃªm tham sá»‘ Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh, cho mÃ´ hÃ¬nh cÃ³ thá»ƒ linh hoáº¡t hÆ¡n trong viá»‡c há»c cÃ¡c Ä‘áº·c trÆ°ng.

{{% /details %}}

{{% details title="F6: layer 84" closed="true" %}}
![alt text](image-14.png)
{{% /details %}}

{{% details title="Output 10" closed="true" %}}
![alt text](image-15.png)

{{% /details %}}

{{% details title="Summary" closed="true" %}}
![alt text](image-16.png)

{{% /details %}}

{{% details title="Code" closed="true" %}}
```python
class LeNet(nn.Module):
    def __init__(self, imdim=3, num_classes=10):
        super(LeNet, self).__init__()

        self.conv1 = nn.Conv2d(imdim, 64, kernel_size=5, stride=1, padding=0)
        self.mp = nn.MaxPool2d(2)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=0)
        self.relu2 = nn.ReLU(inplace=True)
        self.fc1 = nn.Linear(128*5*5, 1024)
        self.relu3 = nn.ReLU(inplace=True)
        self.fc2 = nn.Linear(1024, 1024)
        self.relu4 = nn.ReLU(inplace=True)
        
        self.fc3 = nn.Linear(1024, num_classes)

    def forward(self, x):
        in_size = x.size(0)
        out1 = self.mp(self.relu1(self.conv1(x)))
        out2 = self.mp(self.relu2(self.conv2(out1)))
        out2 = out2.view(in_size, -1)
        out3 = self.relu3(self.fc1(out2))
        out = self.relu4(self.fc2(out3))
        
        return self.fc3(out)
```

{{% /details %}}

## 3. AlexNet

![alt text](image-17.png)

AlexNet lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh CNN Ä‘áº§u tiÃªn giÃ nh chiáº¿n tháº¯ng trong cuá»™c thi ImageNet Large Scale Visual Recognition Challenge (ILSVRC) vÃ o nÄƒm 2012. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ bá»Ÿi Alex Krizhevsky, Ilya Sutskever vÃ  Geoffrey Hinton. MÃ´ hÃ¬nh nÃ y bao gá»“m 8 lá»›p, trong Ä‘Ã³ cÃ³ 5 lá»›p convolutional, 3 lá»›p pooling vÃ  3 lá»›p fully connected.

1. Alex Net bao gá»“m % lá»›p convolutional, 3 lá»›p pooling vÃ  3 lá»›p fully connected.
2. CÃ³ 60 triá»‡u tham sá»‘ vÃ  650.000 neuron vÃ  dÃ¹ng 5 Ä‘áº¿n 6 ngÃ y Ä‘á»ƒ train trÃªn 2 GPU GTX 580 3GB GPUs (2012).
3. AlexNet lÃ  mÃ´ hÃ¬nh Ä‘áº§u tiÃªn sá»­ dá»¥ng GPU Ä‘á»ƒ train.

{{% details title="Overlapping Max Pooling" closed="true" %}}
![alt text](image-18.png)

PhÆ°Æ¡ng phÃ¡p Overlapping nÃ y giÃºp giáº£m lá»—i top-1 thÃªm 0,4% vÃ  lá»—i top-5 thÃªm 0,3% so vá»›i phÆ°Æ¡ng phÃ¡p pooling 2x2 khÃ´ng overlapping (stride 2), trong khi váº«n giá»¯ nguyÃªn kÃ­ch thÆ°á»›c Ä‘áº§u ra.

{{% /details %}}

{{% details title="Activation Function" closed="true" %}}
Qua cÃ¡c bÃ i trÆ°á»›c chÃºng ta Ä‘Ã£ biáº¿t Ä‘Æ°á»£c nhÆ°á»£c Ä‘iá»ƒm cá»§a Tanh váº­y nÃªn AlexNet Ä‘Ã£ sá»­ dá»¥ng ReLU Ä‘á»ƒ thay tháº¿ cho Tanh. ReLU giÃºp mÃ´ hÃ¬nh há»c nhanh hÆ¡n vÃ  giáº£m thiá»ƒu hiá»‡n tÆ°á»£ng vanishing gradient.

![alt text](image-19.png)

{{% /details %}}


{{% details title="Reduce Overfitting" closed="true" %}}
![alt text](image-20.png)

![alt text](image-21.png)

{{% details title="Dropout" closed="true" %}}

Dropout lÃ  má»™t ká»¹ thuáº­t regularization giÃºp giáº£m overfitting báº±ng cÃ¡ch ngáº«u nhiÃªn bá» (drop) má»™t sá»‘ neuron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. CÃ´ng thá»©c toÃ¡n há»c cá»§a nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c chia thÃ nh hai giai Ä‘oáº¡n:  

ğŸ“Œ **1. Giai Ä‘oáº¡n huáº¥n luyá»‡n (Training Phase)**  
Trong giai Ä‘oáº¡n nÃ y, má»™t sá»‘ neuron Ä‘Æ°á»£c **táº¯t Ä‘i** vá»›i xÃ¡c suáº¥t $1 - p$, tá»©c lÃ  chÃºng chá»‰ cÃ³ xÃ¡c suáº¥t $p$ Ä‘Æ°á»£c giá»¯ láº¡i. CÃ´ng thá»©c toÃ¡n há»c nhÆ° sau:  

$$
r_j^{(l)} \sim Bernoulli(p)
$$

$$
\tilde{y}^{(l)} = r^{(l)} \ast y^{(l)}
$$

$$
z_i^{(l+1)} = \mathbf{w}_i^{(l+1)} \tilde{y}^{(l)} + b_i^{(l+1)}
$$

$$
y_i^{(l+1)} = f(z_i^{(l+1)})
$$

- $ r_j^{(l)} $ lÃ  má»™t biáº¿n ngáº«u nhiÃªn Bernoulli vá»›i xÃ¡c suáº¥t $ p$. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  nÃ³ cÃ³ thá»ƒ nháº­n giÃ¡ trá»‹ 1 vá»›i xÃ¡c suáº¥t $ p$ vÃ  giÃ¡ trá»‹ 0 vá»›i xÃ¡c suáº¥t $ 1 - p$.
- $ \tilde{y}^{(l)}$ lÃ  Ä‘áº§u ra sau khi Ã¡p dá»¥ng dropout, tá»©c lÃ  chá»‰ giá»¯ láº¡i má»™t pháº§n giÃ¡ trá»‹ cá»§a táº§ng trÆ°á»›c Ä‘Ã³.
- $ z_i^{(l+1)}$ lÃ  Ä‘áº§u vÃ o cá»§a neuron $ i$ á»Ÿ táº§ng tiáº¿p theo.
- $ y_i^{(l+1)}$ lÃ  Ä‘áº§u ra sau khi Ã¡p dá»¥ng hÃ m kÃ­ch hoáº¡t $ f$ (ReLU, sigmoid,...).

**Hiá»ƒu Ä‘Æ¡n giáº£n:** Má»™t sá»‘ neuron bá»‹ táº¯t Ä‘i, lÃ m cho máº¡ng khÃ´ng dá»±a quÃ¡ nhiá»u vÃ o má»™t sá»‘ Ä‘áº·c trÆ°ng cá»¥ thá»ƒ, giÃºp mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n.

ğŸ“Œ **2. Giai Ä‘oáº¡n suy luáº­n (Test Phase)**  
Trong quÃ¡ trÃ¬nh suy luáº­n, chÃºng ta khÃ´ng bá» neuron ná»¯a, nhÆ°ng vÃ¬ trong lÃºc huáº¥n luyá»‡n ta Ä‘Ã£ loáº¡i bá» má»™t sá»‘ neuron nÃªn cáº§n Ä‘iá»u chá»‰nh láº¡i trá»ng sá»‘ Ä‘á»ƒ giá»¯ nguyÃªn giÃ¡ trá»‹ ká»³ vá»ng. CÃ´ng thá»©c:  

$$
z_i^{(l+1)} = \mathbf{w}_i^{(l+1)} (p \cdot y^{(l)}) + b_i^{(l+1)}
$$

- CÃ¡c trá»ng sá»‘ $w$ Ä‘Æ°á»£c nhÃ¢n vá»›i $p$ Ä‘á»ƒ bÃ¹ láº¡i sá»± giáº£m sá»‘ lÆ°á»£ng neuron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.  
- Äiá»u nÃ y giÃºp giá»¯ nguyÃªn tá»•ng nÄƒng lÆ°á»£ng truyá»n qua máº¡ng, trÃ¡nh lÃ m thay Ä‘á»•i Ä‘áº§u ra mÃ´ hÃ¬nh.

ğŸ“Œ **Ã nghÄ©a thá»±c táº¿**: Khi huáº¥n luyá»‡n, máº¡ng há»c cÃ¡ch hoáº¡t Ä‘á»™ng vá»›i Ã­t neuron hÆ¡n. Khi suy luáº­n, táº¥t cáº£ neuron Ä‘Æ°á»£c sá»­ dá»¥ng, nhÆ°ng trá»ng sá»‘ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ phÃ¹ há»£p vá»›i quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

{{% /details %}}
{{% /details %}}

{{% details title="Summary" closed="true" %}}
![alt text](image-22.png)

{{% /details %}}

{{% details title="Compare AlexNet and LeNet" closed="true" %}}

![alt text](image-23.png)
{{% /details %}}

{{% details title="Code" closed="true" %}}

```python {filename="Data Augmentation"}
train_transform = transforms.Compose(
    [   
        transforms.Resize((70, 70)),
        transforms.RandomCrop((64, 64)),
        transforms.ToTensor(),
        transforms.Normalize([0.4914, 0.4822, 0.4465], 
                             [0.2470, 0.2435, 0.2616]),
    ])

val_transform = transforms.Compose(
    [
        transforms.Resize((70, 70)),
        transforms.RandomCrop((64, 64)),
        transforms.ToTensor(),
        transforms.Normalize([0.4914, 0.4822, 0.4465], 
                             [0.2470, 0.2435, 0.2616])
    ])
```

```python {filename="AlexNet"}
model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

# Replace the last fully-connected layer
model.classifier[6] = nn.Linear(4096, 10)

model = model.to(device)
```
{{% /details %}}

## 4. FZNet

![alt text](image-24.png)

Báº±ng viá»‡c visualizing the convolutional network , ZNet Ä‘Ã£ chiáº¿n tháº¯ng trong cuá»™c thi **ILSVLC2013** táº¡i háº¡ng má»¥c Image Classification báº±ng cÃ¡ch tinh chá»‰nh AlexNet nÄƒm 2012.

{{% details title="Deconv Techniques for Visualization" closed="true" %}}

ğŸ”¹ **QuÃ¡ trÃ¬nh Forward trong CNN** 

Má»™t máº¡ng CNN Ä‘i qua cÃ¡c bÆ°á»›c chÃ­nh sau:  
1. **Convolution (Conv)**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh Ä‘áº§u vÃ o.  
2. **Rectification (Activation Function, vÃ­ dá»¥ ReLU)**: Giá»¯ láº¡i cÃ¡c giÃ¡ trá»‹ cÃ³ Ã½ nghÄ©a, loáº¡i bá» giÃ¡ trá»‹ Ã¢m.  
3. **Pooling (vÃ­ dá»¥ Max Pooling)**: Giáº£m kÃ­ch thÆ°á»›c feature maps, chá»‰ giá»¯ láº¡i thÃ´ng tin quan trá»ng nháº¥t.  

ğŸ”¹ **Deconvolution - QuÃ¡ trÃ¬nh Ä‘áº£o ngÆ°á»£c**  
Deconvnet lÃ  ká»¹ thuáº­t ngÆ°á»£c láº¡i vá»›i cÃ¡c bÆ°á»›c trÃªn, giÃºp chÃºng ta tháº¥y Ä‘Æ°á»£c cÃ¡ch CNN â€œhiá»ƒuâ€ dá»¯ liá»‡u.  

1. Unpooling (ngÆ°á»£c vá»›i Pooling)
2. Deconvolution (ngÆ°á»£c vá»›i Convolution)
3. ReLU Inversion (ngÆ°á»£c vá»›i Activation Function)
ğŸ”¥ **Má»¥c Ä‘Ã­ch cá»§a Deconvnet**
- **Trá»±c quan hÃ³a Ä‘áº·c trÆ°ng**: Cho tháº¥y má»—i lá»›p trong CNN há»c Ä‘Æ°á»£c nhá»¯ng gÃ¬ tá»« hÃ¬nh áº£nh Ä‘áº§u vÃ o.  
- **Debug mÃ´ hÃ¬nh**: GiÃºp kiá»ƒm tra xem máº¡ng cÃ³ há»c Ä‘Ãºng Ä‘áº·c trÆ°ng hay khÃ´ng.  
- **Giáº£i thÃ­ch mÃ´ hÃ¬nh**: Há»— trá»£ giáº£i thÃ­ch cÃ¡ch CNN Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, há»¯u Ã­ch trong AI minh báº¡ch (Explainable AI).  

{{% /details %}}

{{% details title="1. Unpooling (ngÆ°á»£c vá»›i Pooling)" closed="true" %}}
- Khi Pooling giá»¯ láº¡i giÃ¡ trá»‹ lá»›n nháº¥t trong má»—i vÃ¹ng, Unpooling sáº½ Ä‘áº·t láº¡i giÃ¡ trá»‹ Ä‘Ã³ vÃ o vá»‹ trÃ­ ban Ä‘áº§u vÃ  gÃ¡n cÃ¡c vá»‹ trÃ­ khÃ¡c báº±ng 0.
  
- Äiá»u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch lÆ°u láº¡i vá»‹ trÃ­ cá»§a giÃ¡ trá»‹ lá»›n nháº¥t trong quÃ¡ trÃ¬nh Pooling (gá»i lÃ  "Switches").  

![alt text](image-25.png)
{{% /details %}}
  
{{% details title="2. Deconvolution (ngÆ°á»£c vá»›i Convolution)" closed="true" %}}
- Thay vÃ¬ sá»­ dá»¥ng bá»™ lá»c Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng, Deconvolution sá»­ dá»¥ng cÃ¡c phÃ©p toÃ¡n Ä‘áº£o ngÆ°á»£c Ä‘á»ƒ tÃ¡i táº¡o láº¡i hÃ¬nh áº£nh ban Ä‘áº§u tá»« feature maps.
![alt text](image-27.png)
{{% /details %}}

{{% details title="3. ReLU Inversion (ngÆ°á»£c vá»›i Activation Function)" closed="true" %}}
- Náº¿u trÆ°á»›c Ä‘Ã³ ReLU loáº¡i bá» giÃ¡ trá»‹ Ã¢m, bÃ¢y giá» chÃºng ta khÃ´i phá»¥c láº¡i nhá»¯ng vÃ¹ng Ä‘Ã³.

![alt text](image-28.png)

![alt text](image-29.png)

![alt text](image-30.png)

![alt text](image-31.png)

![alt text](image-32.png)

+ Summary:

  ![alt text](image-33.png)
{{% /details %}}

{{% details title="Visualization for Each Layer" closed="true" %}}
![alt text](image-34.png)

ğŸ”¹ Layer 1 - Há»c biÃªn vÃ  há»a tiáº¿t Ä‘Æ¡n giáº£n:
+ Nháº­n diá»‡n cÃ¡c táº§n sá»‘ tháº¥p vÃ  cao, nhÆ°ng khÃ´ng cÃ³ táº§n sá»‘ trung bÃ¬nh.
+ Chá»§ yáº¿u lÃ  cÃ¡c bá»™ lá»c cáº¡nh, gÃ³c, Ä‘Æ°á»ng chÃ©o vÃ  biÃªn Ä‘á»™ sÃ¡ng. ÄÃ¢y lÃ  cÃ¡c Ä‘áº·c trÆ°ng cÆ¡ báº£n nháº¥t cá»§a hÃ¬nh áº£nh.

ğŸ”¹ Layer 2 - Há»c cÃ¡c há»a tiáº¿t phá»©c táº¡p hÆ¡n
+ Xuáº¥t hiá»‡n váº¥n Ä‘á» aliasing (nhiá»…u do máº¥t thÃ´ng tin khi sampling). 
+ Báº¯t Ä‘áº§u nháº­n diá»‡n cÃ¡c máº«u láº·p láº¡i nhÆ° há»a tiáº¿t váº£i, hoa vÄƒn Ä‘Æ¡n giáº£n.

ğŸ”¹ Layer 3 - Há»c cÃ¡c máº«u tá»•ng quÃ¡t hÆ¡n: 
+ Báº¯t Ä‘áº§u há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p hÆ¡n, cháº³ng háº¡n nhÆ° cáº¥u trÃºc hÃ¬nh há»c. 
+ Nháº­n diá»‡n cÃ¡c pháº§n nhá» cá»§a Ä‘á»‘i tÆ°á»£ng, vÃ­ dá»¥: má»™t pháº§n bÃ¡nh xe, má»™t pháº§n khuÃ´n máº·t. 

ğŸ”¹ Layer 4 - Há»c Ä‘áº·c trÆ°ng mang tÃ­nh ngá»¯ nghÄ©a cao hÆ¡n: 
+ CÃ¡c Ä‘áº·c trÆ°ng trá»Ÿ nÃªn cÃ³ Ã½ nghÄ©a hÆ¡n vá»›i tá»«ng loáº¡i Ä‘á»‘i tÆ°á»£ng cá»¥ thá»ƒ. VÃ­ dá»¥: cÃ³ thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c khuÃ´n máº·t chÃ³, chÃ¢n chim.

ğŸ”¹ Layer 5 - Nháº­n diá»‡n toÃ n bá»™ Ä‘á»‘i tÆ°á»£ng 
+ á» lá»›p sÃ¢u nháº¥t, CNN cÃ³ thá»ƒ nháº­n diá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng hoÃ n chá»‰nh vá»›i nhiá»u tÆ° tháº¿ khÃ¡c nhau. VÃ­ dá»¥: bÃ n phÃ­m, chÃ³, hoa, ngÆ°á»i.

{{% /details %}}

{{% details title="Modifications of AlexNet Based on Visualization Results" closed="true" %}}
![alt text](image-35.png)

ZFNet lÃ  má»™t kiáº¿n trÃºc máº¡ng nÆ¡-ron Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a AlexNet.

1. **Giáº£m KÃ­ch ThÆ°á»›c Bá»™ Lá»c**: ZFNet giáº£m kÃ­ch thÆ°á»›c bá»™ lá»c á»Ÿ lá»›p 1 vÃ  lá»›p 2 tá»« 11x11 xuá»‘ng 7x7, giÃºp tÄƒng cÆ°á»ng kháº£ nÄƒng phÃ¡t hiá»‡n cÃ¡c Ä‘áº·c trÆ°ng nhá» hÆ¡n trong hÃ¬nh áº£nh.

2. **Thay Äá»•i Stride**: ZFNet Ä‘iá»u chá»‰nh stride (bÆ°á»›c nháº£y) cá»§a lá»›p convolution Ä‘áº§u tiÃªn tá»« 4 xuá»‘ng 2, cho phÃ©p máº¡ng há»c Ä‘Æ°á»£c nhiá»u thÃ´ng tin hÆ¡n tá»« cÃ¡c Ä‘áº·c trÆ°ng trong hÃ¬nh áº£nh.

3. **Bá»• Sung CÃ¡c Ká»¹ Thuáº­t**: Máº¡ng nÃ y cÅ©ng sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° Local Response Normalization vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p pooling khÃ¡c Ä‘á»ƒ tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»c.

Nhá»¯ng thay Ä‘á»•i nÃ y giÃºp ZFNet cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng tá»•ng quÃ¡t so vá»›i AlexNet.

{{% /details %}}

{{% details title=" Local Response Normalization" closed="true" %}}

{{% details title=" Inter-Channel LRN" closed="true" %}}
![alt text](image-36.png)

![alt text](image-37.png)

{{% /details %}}

{{% details title=" Intra-Channel LRN" closed="true" %}}
![alt text](image-38.png)
![alt text](image-39.png)
{{% /details %}}

{{% /details %}}

{{% details title="Comparison of the two normalization techniques in DNNs" closed="true" %}}
![alt text](image-40.png)

+ LRN (Local Response Normalization):
  + CÃ³ thá»ƒ huáº¥n luyá»‡n: KhÃ´ng.
  + Tham sá»‘ huáº¥n luyá»‡n: 0.
  + Táº­p trung vÃ o: á»¨ng dá»¥ng á»©c cháº¿ lÃ¢n cáº­n.
+ BN (Batch Normalization):
  + CÃ³ thá»ƒ huáº¥n luyá»‡n: CÃ³.
  + Tham sá»‘ huáº¥n luyá»‡n: 2 (tá»‰ lá»‡ vÃ  dá»‹ch).
  + Táº­p trung vÃ o: Äá»‘i phÃ³ vá»›i Internal Covariate Shift (ICF).

{{% details title="Internal Covariate Shift" closed="true" %}}
ICF (Internal Covariate Shift) lÃ  khÃ¡i niá»‡m trong há»c sÃ¢u mÃ´ táº£ sá»± thay Ä‘á»•i phÃ¢n phá»‘i cá»§a Ä‘áº§u ra tá»« cÃ¡c lá»›p trÆ°á»›c trong máº¡ng nÆ¡-ron khi cÃ¡c tham sá»‘ cá»§a máº¡ng Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. 

### Äiá»ƒm chÃ­nh vá» ICF:

1. **Váº¥n Ä‘á»**: Khi huáº¥n luyá»‡n máº¡ng nÆ¡-ron, cÃ¡c phÃ¢n phá»‘i Ä‘áº§u ra cá»§a tá»«ng lá»›p cÃ³ thá»ƒ thay Ä‘á»•i liÃªn tá»¥c. Äiá»u nÃ y khiáº¿n cho cÃ¡c lá»›p sau pháº£i Ä‘iá»u chá»‰nh liÃªn tá»¥c Ä‘á»ƒ thÃ­ch á»©ng vá»›i cÃ¡c phÃ¢n phá»‘i má»›i, lÃ m cháº­m quÃ¡ trÃ¬nh há»™i tá»¥.

2. **Há»‡ quáº£**: ICF cÃ³ thá»ƒ dáº«n Ä‘áº¿n viá»‡c mÃ´ hÃ¬nh há»c cháº­m hÆ¡n vÃ  khÃ³ khÄƒn hÆ¡n trong viá»‡c tá»‘i Æ°u hÃ³a, vÃ¬ má»—i lá»›p pháº£i há»c tá»« Ä‘áº§u má»—i khi tham sá»‘ cá»§a lá»›p trÆ°á»›c thay Ä‘á»•i.

3. **Giáº£i phÃ¡p**: Batch Normalization Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ giáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a ICF báº±ng cÃ¡ch chuáº©n hÃ³a Ä‘áº§u ra cá»§a má»—i lá»›p, giá»¯ cho phÃ¢n phá»‘i Ä‘áº§u ra á»•n Ä‘á»‹nh hÆ¡n trong suá»‘t quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Báº±ng cÃ¡ch nÃ y, máº¡ng nÆ¡-ron cÃ³ thá»ƒ há»c nhanh hÆ¡n vÃ  hiá»‡u quáº£ hÆ¡n.

![alt text](image-41.png)
{{% /details %}}
{{% /details %}}

## 5. VGGNet

VGG lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh CNN ná»•i tiáº¿ng Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Visual Geometry Group (VGG) táº¡i Äáº¡i há»c Oxford vÃ o nÄƒm 2014. MÃ´ hÃ¬nh nÃ y bao gá»“m 16-19 lá»›p, trong Ä‘Ã³ cÃ³ 13 lá»›p convolutional vÃ  3 lá»›p fully connected.

![alt text](image-42.png)

{{% details title="VGG16Net" closed="true" %}}
![alt text](image-43.png)

AlexNet, ra máº¯t nÄƒm 2012, lÃ  má»™t bÆ°á»›c Ä‘á»™t phÃ¡ trong máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN), trá»Ÿ thÃ nh mÃ´ hÃ¬nh hÃ ng Ä‘áº§u cho phÃ¢n loáº¡i hÃ¬nh áº£nh vá»›i bá»™ lá»c 11x11 vÃ  bÆ°á»›c nháº£y 4 á»Ÿ lá»›p Ä‘áº§u tiÃªn. CÃ¡c cáº£i tiáº¿n sau nÃ y, nhÆ° ZFNet, Ä‘Ã£ Ä‘iá»u chá»‰nh kÃ­ch thÆ°á»›c bá»™ lá»t xuá»‘ng 7x7 vÃ  bÆ°á»›c nháº£y xuá»‘ng 2, giÃºp nÃ¢ng cao kháº£ nÄƒng phÃ¡t hiá»‡n Ä‘áº·c trÆ°ng vÃ  má»Ÿ Ä‘Æ°á»ng cho nhiá»u mÃ´ hÃ¬nh má»›i trong lÄ©nh vá»±c nÃ y. Vá»›i VGG sá»­ dá»¥ng bá»™ lá»c 3x3 lÃ m mÃ´ hÃ¬nh trá»Ÿ nÃªn hiá»‡u quáº£ hÆ¡n ná»¯a.

![alt text](image-44.png)

![alt text](image-45.png)
{{% /details %}}

{{< callout type="warning" >}}
  Táº¡i vÃ¬ VGG16net cÃ³ 16 layer cÃ³ tham sá»‘ nÃªn Ä‘Æ°á»£c gá»i lÃ  VGG16net
{{< /callout >}}

{{% details title="VGGNet" closed="true" %}}
![alt text](image-46.png)

![alt text](image-47.png)

{{% /details %}}

## 6. GoogleLeNet

{{% details title="Motivation" closed="true" %}}
+ Má»™t gÃ³c nhÃ¬n khÃ¡c cá»§a backpropagation algorithm.

![alt text](image-48.png)

{{< callout type="error" >}}
KÃ­ch thÆ°á»›c máº¡ng neuron lá»›n dáº«n Ä‘áº¿n sá»‘ lÆ°á»£ng tham sá»‘ lá»›n hÆ¡n, lÃ m tÄƒng nguy cÆ¡ overfiting, Ä‘áº·c biá»‡t vá»›i dataset nhá».
KÃ­c thÆ°á»›c neuron tÄƒng cÅ©ng lÃ m cho tiÃªu tá»‘n tÃ i nguyÃªn tÃ­nh toÃ¡n hÆ¡n
{{< /callout >}}

{{% details title="Solution" closed="true" %}}
Giá»›i thiá»‡u tÃ­nh thÆ°a (sparsity) vÃ  thay tháº¿ cÃ¡c lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ báº±ng cÃ¡c lá»›p thÆ°a, ngay cáº£ bÃªn trong cÃ¡c phÃ©p tÃ­ch cháº­p (convolutions).

![alt text](image-49.png)

{{% /details %}}

{{% /details %}}

{{% details title="Inception Net" closed="true" %}}

{{< callout  >}}
  1x1 Convoluation Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t module giáº£m chiá»u dá»¯ liá»‡u dáº«n Ä‘áº¿n giáº£m viá»‡c tÃ­nh toÃ¡n.
{{< /callout >}}

ChÃºng ta giáº£ sá»­ chÃºng ta cáº§n chuyá»ƒn tá»« shape (28, 28, 192) sang (28, 28, 32)

Náº¿u chÃºng ta sá»­ dá»¥ng Convolution 5x5 Ä‘á»ƒ chuyá»ƒn tá»« (28, 28, 192) sang (28, 28, 32).
![alt text](image-51.png)

Náº¿u chÃºng ta sá»­ dá»¥ng 1 convolution 1x1 vÃ  1 convolution 5x5.

![alt text](image-52.png)

Tá»« hai hÃ¬nh áº£nh trÃªn viá»‡c thÃªm conv1x1 lÃ m giáº£m tham sá»‘ lÆ°á»£ng parameter. Theo nhÆ° tÃ¡c giáº£ nháº­n Ä‘á»‹nh viá»‡c chÃºng ta Ä‘i Ä‘Æ°á»£c sÃ¢u sáº½ tá»‘t hÆ¡n so vá»›i viá»‡c chÃºng ta Ä‘i khÃ´ng Ä‘Æ°á»£c sÃ¢u mÃ  cÃ³ nhiá»u tham sá»‘.

![alt text](image-53.png)
![alt text](image-54.png)
{{% /details %}}

{{% details title="Inception Module" closed="true" %}}

![alt text](image-55.png)

![alt text](image-56.png)
{{% /details %}}

![alt text](image-57.png)

VÃ o thá»i Ä‘iá»ƒm báº¥y giá» viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh vá»›i 22 layer khÃ¡ phá»©c táº¡p bá»Ÿi khÃ´ng cÃ³ Ä‘á»§ tÃ i nguyÃªn Ä‘á»ƒ thá»±c hiá»‡n.

## 7. ResNet
![alt text](image-59.png)

{{% details title="Skip connection" closed="true" %}}
![alt text](image-60.png)

Trong deeplearning váº¥n Ä‘á» **vanishing gradient**, viá»‡c thÃªm layer vá»«a pháº£i sáº½ giÃºp mÃ´ hÃ¬nh há»c tá»‘t hÆ¡n. NhÆ°ng khi chÃºng ta thÃªm nhiá»u layer quÃ¡ láº¡i lÃ m cho mÃ´ hÃ¬nh há»c khÃ´ng Ä‘Æ°á»£c tá»‘t ná»¯a gÃ¢y ra váº¥n Ä‘á» vanishing gradient.

Skip connection giÃºp giáº£i quyáº¿t váº¥n Ä‘á» vanishing gradient. Skip connection giÃºp cho gradient cÃ³ thá»ƒ truyá»n qua cÃ¡c layer mÃ  khÃ´ng bá»‹ giáº£m Ä‘i nhiá»u.

![alt text](image-61.png)

![alt text](image-62.png)

Kiáº¿n trÃºc máº¡ng **ResNet** dá»±a trÃªn máº¡ng 34 lá»›p Ä‘Æ¡n giáº£n láº¥y cáº£m há»©ng tá»« **VGG-19**, vÃ  thÃªm cÃ¡c káº¿t ná»‘i ngáº¯n. Nhá»¯ng káº¿t ná»‘i nÃ y giÃºp cÃ¡c gradient dá»… dÃ ng truyá»n qua máº¡ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, giáº£m thiá»ƒu váº¥n Ä‘á» gradient biáº¿n máº¥t vÃ  cho phÃ©p Ä‘Ã o táº¡o cÃ¡c máº¡ng sÃ¢u hÆ¡n.

{{% /details %}}

{{% details title="Residual Block" closed="true" %}}
![alt text](image-63.png)

+ **Identity mapping**: Gradient Ä‘i qua mÃ  khÃ´ng gáº·p pháº£i báº¥t ká»³ trá»ng sá»‘ nÃ o, giá»¯ nguyÃªn giÃ¡ trá»‹. Ãnh xáº¡ Ä‘á»“ng nháº¥t cho phÃ©p thÃ´ng tin cháº£y qua mÃ  khÃ´ng bá»‹ thay Ä‘á»•i, giÃºp duy trÃ¬ giÃ¡ trá»‹ gradient trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

+ **Residual mapping**: Gradient Ä‘i qua cÃ¡c trá»ng sá»‘, cÃ³ thá»ƒ gÃ¢y ra sá»± thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ.
{{% /details %}}


{{% details title="Resnet version" closed="true" %}}
![alt text](image-64.png)

![alt text](image-65.png)
{{% /details %}}

{{% details title="ResNet34" closed="true" %}}
![alt text](image-66.png)
![alt text](image-67.png)
![alt text](image-68.png)

+ Má»—i lá»›p cá»§a ResNet bao gá»“m má»™t sá»‘ khá»‘i

![alt text](image-69.png)

![alt text](image-70.png)

CÃ³ 2 loáº¡i shortcut lÃ :
+ identity Shortcut: lÃ  Ä‘Æ°á»ng Ä‘i khÃ´ng tham sá»‘ mÃ  á»Ÿ Ä‘Ã³ khi káº¿t há»£p láº¡i nÃ³ cÃ¹ng shape.
+ projection shortcut: ngÆ°á»£c láº¡i khi káº¿t há»£p vá»›i Ä‘Æ°á»ng Residual Mapping hai Ä‘Æ°á»ng khÃ´ng cÃ¹ng shape.

{{% details title="CÃ¡ch giáº£i quyáº¿t projection shortcut" closed="true" %}}
![alt text](image-71.png)

C1: Sá»­ dá»¥ng Conv vá»›i stride Ä‘á»ƒ downsampling dá»¯ liá»‡u.
C2: Sá»­ dá»¥ng Conv 1x1 Ä‘i kÃ¨m vá»›i Conv Ä‘á»ƒ giáº£m parameters ná»¯a.
{{% /details %}}

![alt text](image-72.png 'Overview Residual Block')
{{% /details %}}

{{% details title="RetNet50" closed="true" %}}
![alt text](image-73.png)

![alt text](image-74.png)

![alt text](image-75.png)

{{% /details %}}

## 8. MobileNet

![alt text](image-76.png)

{{% details title="Motivation" closed="true" %}}

VÃ¬ Ä‘iá»‡n thoáº¡i di Ä‘á»™ng cÃ³ bá»™ nhá»› RAM giá»›i háº¡n vÃ¬ váº­y viá»‡c Ã¡p dá»¥ng má»™t mÃ´ hÃ¬nh cÃ³ parameters khÃ¡ lá»›n sáº½ lÃ m cho Ä‘iá»‡n thoáº¡i khÃ³ khÄƒn trong viá»‡c sá»­ dá»¥ng tÃ i nguyÃªn cÃ³ thá»ƒ gÃ¢y ra viá»‡c trÃ n bá»™ nhá»›. VÃ¬ cáº­y cÃ¡c nhÃ  khoa há»c muá»‘n má»™t phÆ°Æ¡ng Ã¡p tuy Ä‘Ã¡n Ä‘á»•i parameters nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c váº«n pháº£i á»Ÿ má»©c cháº¥p nháº­n Ä‘Æ°á»£c. MobileNet Ä‘Æ°á»£c ra Ä‘á»i vÃ o nÄƒm 2017 bá»Ÿi Google. MobileNet phiÃªn báº£n nhá» nháº¥t sá»­ dá»¥ng khoáº£ng 1.3 tr tham sá»‘. Trong khi Ä‘Ã³ má»™t VGG model cáº§n sá»­ dá»¥ng 500MB disk space, mobileNet chá»‰ cáº§n 16-18Mb.
{{% /details %}}

![alt text](image-77.png 'So sÃ¡nh giá»¯a MobileNet vÃ  cÃ¡c model trÆ°á»›c Ä‘Ã³')

Hai ká»¹ thuáº­t chÃ­nh giÃºp giáº£m sá»‘ lÆ°á»£ng tham sá»‘:
+ Depthwise Separable Convolution
+ Two shrinking Hyperparameters: width multiplier vÃ  resolution multiplier.

{{% details title="Depthwise Separable Convolution" closed="true" %}}

![alt text](image-78.png)

TrÃªn hÃ¬nh áº£nh lÃ  phÆ°Æ¡ng phÃ¡p conv truyá»n thá»‘ng chung ta hay lÃ m vÃ  phÆ°Æ¡ng phÃ¡p Depthwise Separable Convolution. Váº­y chÃºng ta thá»­ so sÃ¡nh giá»¯a chÃºng.
![alt text](image-79.png)

HÃ¬nh áº£nh trÃªn lÃ  phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c tá»‘n khoáº£ng 2160 phÃ©p tÃ­nh.


Äáº§u tiÃªn chÃºng ta sáº½ thá»±c hiá»‡n Depthwise Convolution sau Ä‘Ã³ sáº½ thá»±c hiá»‡n Pointwise Convolution.
![alt text](image-81.png)

Vá»›i chi phÃ­ tÃ­nh toÃ¡n cá»§a Depthwise Convolution vÃ  Pointwise Convolution lÃ :

![alt text](image-82.png)

![alt text](image-83.png)

Tá»•ng káº¿t láº¡i chi phÃ­ cá»§a cáº£ hai phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c tÃ³m táº¯t nhÆ° sau:

![alt text](image-84.png)

ChÃºng ta tháº¥y tráº£ vá» cÃ¹ng shape nhÆ°ng phÆ°Æ¡ng phÃ¡p thá»© 2 tráº£ vá» sá»‘ parameters Ã­t hÆ¡n.

{{% /details %}}

{{% details title="Depthwise apply on MobileNet" closed="true" %}}
![alt text](image-85.png)

+ Thá»±c hiá»‡n riÃªng biá»‡t cho tá»«ng kÃªnh Ä‘áº§u vÃ o.
+ Má»—i kÃªnh mÃ u sáº½ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi má»™t bá»™ lá»c riÃªng, tá»©c lÃ  má»—i bá»™ lá»c chá»‰ hoáº¡t Ä‘á»™ng trÃªn má»™t kÃªnh duy nháº¥t.
+ Äáº§u ra tá»« má»—i kÃªnh sáº½ Ä‘Æ°á»£c káº¿t há»£p láº¡i Ä‘á»ƒ táº¡o ra má»™t tensor Ä‘áº§u ra 3D.

![alt text](image-86.png)

+ Sá»­ dá»¥ng má»™t bá»™ lá»c 1x1 Ä‘á»ƒ káº¿t há»£p cÃ¡c kÃªnh Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ tá»« bÆ°á»›c trÆ°á»›c, cho phÃ©p táº¡o ra má»™t sá»‘ lÆ°á»£ng kÃªnh Ä‘áº§u ra tÃ¹y Ã½.
{{% /details %}}

{{% details title="CÃ´ng thá»©c" closed="true" %}}
![alt text](image-87.png)
![alt text](image-88.png)

Tá»‰ lá»‡ giá»¯a conv truyá»n thá»‘ng vÃ  Depthwise Separable Convolution lÃ :
![alt text](image-89.png)
{{% /details %}}

{{% details title="Why is DepthwiseSeparable Convolution so efficient" closed="true" %}}
![alt text](image-90.png)

{{% /details %}}

{{% details title=" Shrinking Hyperparameters" closed="true" %}}
+ **Width Multiplier trong MobileNet: CÃ¡c MÃ´ HÃ¬nh Má»ng HÆ¡n**
  ![alt text](image-91.png)

+ **Resolution multiplier which adjusts the spatial dimensions of the feature maps and the input image: Reduced Representation**
  ![alt text](image-92.png)
{{% /details %}}

{{% details title="Summary" closed="true" %}}

![alt text](image-93.png 'overview MobileNet')

![alt text](image-94.png)

{{% /details %}}
## 9. ConvNext

## 10. Performance Evaluate on Cifar10 Dataset
